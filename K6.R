# Kapittel 6 - Deskriptiv statistikk
 
# sentraltendens - aritmetisk gjennomsnitt

library(rnorsk)
data("olympic")

hoeyde <- filter(olympic, Sex=="F", !is.na(Height)) %>% 
  pull(Height)

sum(hoeyde)/length(hoeyde) # summerer alle høyder
# antall elementer i variabelen "hoeyde"
# Dette gir gjennomsnitt

# Enklere
mean(hoeyde)

# Lage histogram
ggplot(data.frame(hoeyde),aes(x=hoeyde)) + 
  geom_histogram(bins=15)+
  # beregn og vis gjennomsnitt som rød linje
  geom_vline(xintercept = mean(hoeyde), 
             color="red")      

# sentraltendens - median
median(hoeyde) # mer robust mot utliggere

#eks
hoeyde.med.utligger <- c(hoeyde, 160000) # feiltasting
mean(hoeyde.med.utligger) 
median(hoeyde.med.utligger) 

# sentraltendens - modus
# verdien som hyppisk forekommer i en variabels fordeling
# vil være det samme som den "høyeste" toppen i fordelingsplottet
library(modeest) # aktuell pakke
mlv(hoeyde) # funksjonen som beregner modus

# Spredning
# Varians
# Summen av kvadrete avvik fra gjennomsnittet delt på "n-1"
sum( ( hoeyde-mean(hoeyde) )^2 ) / (length(hoeyde)-1)
var(hoeyde)

# Standardavvik - kvadratroten til Variansen
sd(hoeyde) # forutsetter at dataene er tilnærmet normalfordelte
# Andre funksjoner
range(hoeyde) # avstanden mellom høyeste og laveste verdi
min(hoeyde)
max(hoeyde)
IQR(hoeyde) # interkvartilavstanden - tredje minus første kvantil
# bredden til intervallet som inneholder de midterste 50 % av dataene
quantile(hoeyde) # deler dataene i kvartiler som standard
quantile(hoeyde, probs=c(0.05, 0.10, 0.9, 0.95)) # tilleggsargument for å 
# bestemme hvilke kvantiler som skal beregnes

library(moments)
skewness(hoeyde)
# at en fordeling ikke er symmetrisk rundt gjennomsnittet. Negativ verdi betyr 
# en venstreskjev fordeling,og positiv at den er høyreskjev.

kurtosis(hoeyde)
# Tilstand når en fordeling er normalfordelt, men at halene har for lave eller 
# for høye verdier til å være normalfordelt("fat tails")
# kurtosis er et positivt tall
# for en normalfordelt variabel er verdien nær 3 - mesokurtic
# Mindre enn 3 - platykurtic - det finnes mindre ekstreme verdier enn forventet
# utfra normalfordelingen
# Større enn 3 - leptokurtic - det finnes flere ekstreme verdier enn forventet
# utfra normalfordelingen

# Eks tre forskjellige datasett
# normalfordelt - "hoeyde" høyde kvinnelige olympiadeltakere
# venstreskjev fordeling - "doede" dødsfall i Norge 2016
# høyreskjev fordeling - "leilighet" boligpriser i Trondheim
dodsalder <- doede %>% uncount(doede) %>% pull(alder)
pris <- leilighet %>% pull(pris)

tribble(
  ~dataset,    ~skewness,           ~kurtosis,
  "olympic",   skewness(hoeyde),    kurtosis(hoeyde),
  "doede",     skewness(dodsalder), kurtosis(dodsalder),
  "leilighet", skewness(pris),      kurtosis(pris)
)

# Diskrete fordelinger
# ikke mulig å beregne mean av en kategorisk variabel
# frekvenstabell
table(olympic$Sex)
table(olympic$Medal, useNA="always") # alle deltakerne tas med

# bruker dplyr
olympic %>% 
  group_by(Medal) %>% 
  summarise(antall=n()) # beregner antall obs i hvert deldatasett og lager en
# variabel antall som inneholder denne infoen

length( unique(olympic$Team) ) # teller antall land som var 
# unique angir alle unike verdier i datasettet
# length teller totalt antall verdier

# Dette stemmer ikke med de offisielle deltakerlistene som sier 207 deltakerland
teams <- unique(olympic$Team)
tail(teams) # ser at noen land er tatt med to ganger, rydder i dette:

land <- teams[!str_detect(teams, "-")] # Tar bare med de landene uten "-"
length(land)

# hvor mange fra hvert land, og hvem hadde flest?
olympic %>% 
  group_by(Team) %>%
  summarise(antall=n()) %>% 
  arrange(desc(antall)) %>% # sorterer
  head(10)

# Bruker summary() for å få oversikt over et datasett:
summary(studentHeights)

# Summarytools
# descr() - beskriver bare kontinuerlige variabler
# freq() - frekvens diskrete variabler, må brukes på en og en variabel
library(summarytools)
descr(olympic)

freq(olympic$Medal)

# dfSummary() - gir omfattende beskrivelse av hele datasettet, alle typer variabler

dfSummary(studentHeights)

# Skimr() - annen pakke som sammenfatter variabler
library(skimr)
olympic %>% skim(Team,Height,Weight)

# sammenlikne høyde og vekt hos utøverne:
olympic %>% group_by(Sex) %>% 
  skim(Team,Height,Weight)

# hente ut de numeriske variablene
olympic %>% group_by(Sex) %>% 
  skim(Team,Height,Weight) %>%
  filter(skim_type=="numeric") # henter de numeriske variablene 

# Korrelasjon

# beskriver sammenhengen mellom to eller flere variabler
# med Base R:
# sammenhengen mellom høyde og vekt hos kvinner
# henter først kvinnene og utelater rader med na:
olympic.kvinner <- olympic %>% 
  filter(Sex=="F") %>% 
  na.omit

hoeyde <- pull(olympic.kvinner, Height) # plukke ut variablen
vekt <- pull(olympic.kvinner, Weight)
cor(hoeyde,vekt)

# datasett med bare numeriske variabler
big.five <- epi.bfi %>% select(starts_with("bf")) # velger variabler som starter med
cor(big.five)
# Symmetrien gjør at vi trenger bare halvparten av verdiene:
lowerCor(big.five) # fra psych-pakken

# korrelasjoner er definert mellom kontinuerlige variabler. Triks å plukke ut disse
# fra datarammen

olympic.kvinner %>% 
  lowerCor

olympic.kvinner %>% 
  select_if(is.numeric) %>% 
  lowerCor

# krysstabulering
table(studentHeights$kjoenn, studentHeights$aar)

# ctable fra summarytools angir også prosent, begrenset til to var samtidig
ctable(studentHeights$kjoenn,studentHeights$aar)

# Ved flere må vi bruke table():
olympic.ball <- olympic %>% 
  filter(Sport %in% c("Basketball", "Football", "Volleyball")) %>% 
  select(Sport,Medal,Sex)
table(olympic.ball)

# Sammenfatte variabler på tvers av grupper:
library(e1071)
olympic %>% 
  group_by(Sex) %>% ## del inn mannlige vs. kvinnlige utøvere
  filter(!is.na(Height)) %>% ## ta bort missing values
  summarise(gjennomsnitt=mean(Height), ## NB: bruker summarise med s, beregn gjennomsnitt,
            median=median(Height),     ## median mfl.
            sd=sd(Height),
            skjevhet=skewness(Height),
            kurtosis=kurtosis(Height))

# Annet eksempel:
data("stroop")
str(stroop)
# 9 variabler og 49309 rader
# 85 forskjellige deltakere som hver har bidratt med mange rader
# se på reaksjonstiden til de ulike deltakerne i variablen RT
# plukker ut reaksjonstiden for en tilfeldig person og beregner gjennomsnittet:
RT <- stroop %>% 
  filter(subj=="120554") %>% 
  pull(RT)
mean(RT)

# vil gjøre det for alle 85 deltakere:
library(dplyr)
mean.rt <- stroop %>% 
  group_by(subj) %>%
  summarise(mean.RT=mean(RT,na.rm=T)) #NB: bruker summarise med s
str(mean.rt)

# dette gir oss et datasett som består av 85 rader og to variabler(subj og mean)

# Gruppegjennomsnittet til de gjennomsnittlige reaksjonstidene
mean.rt %>%
  summarise(gruppegjennomsnitt=mean(mean.RT),
            median=median(mean.RT),
            sd=sd(mean.RT),
            skevhet=skewness(mean.RT),
            kurtosis=kurtosis(mean.RT))

# Eksempel - se side 185
# utvider group_by kommandoen med condition

mean.rt.cond <- stroop %>% 
  group_by(subj,condition) %>%
  summarise(mean.RT=mean(RT,na.rm=T)) 
head(mean.rt.cond)

# Vi har nå et datasett med tre variabler
# kjører samme sammenfatning som i linje 211
mean.rt.cond %>%
  group_by(condition) %>%
  summarise(gruppegjennomsnitt.RT=mean(mean.RT)) 































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































